{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터\n",
    "---\n",
    "- 데이터는 QnA데이터로 총 11,823의 대화가 있습니다.\n",
    "- label은 0 [일상], 1 [부정], 2 [긍정] 이 있습니다.\n",
    "- 총 데이터 크기는 약 869KB 입니다.\n",
    "\n",
    "데이터 예시는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\loveg\\Downloads\\Chatbot_data-master\\ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로더\n",
    "\n",
    "- 위의 data를 불러올 데이터 로더 클래스를 선언 합니다.\n",
    "- 데이터를 Q와 A를 이어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.conversation_data = []\n",
    "        self.end_of_text_token = \"</s>\"\n",
    "\n",
    "        header = 0\n",
    "        with open(data_path, encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "            for row in csv_reader:\n",
    "                if header == 0:\n",
    "                    header += 1\n",
    "                    continue\n",
    "                _type = [\"일상\", \"부정\", \"긍정\"][int(row[2])]\n",
    "                temp_converation = [f\"{_type}: {row[0]}{self.end_of_text_token}\", f\"{row[1]}{self.end_of_text_token}\"]\n",
    "                self.conversation_data.append(temp_converation)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conversation_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.conversation_data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디바이스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 설정\n",
    "\n",
    "- BATCH_SIZE : 데이터 로더의 배치 사이즈를 설정합니다.\n",
    "- EPOCHS : Fine-Tuning할 Epoch을 설정합니다.\n",
    "- LEARNING_RATE : 모델 학습시, lr을 설정합니다.\n",
    "- WARMUP_STEPS : 스케쥴러의 warmup을 진행할 step을 설정합니다.\n",
    "- DATA_PATH : Fine-Tuning에 사용할 데이터 경로를 지정합니다.\n",
    "- MODEL_TYPE : 허깅페이스의 KoGPT-2를 설정합니다.\n",
    "- OUTPUT_FOLDER : 모델 저장 경로를 지정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 100\n",
    "MAX_SEQ_LEN = 100\n",
    "DATA_PATH = r\"C:\\Users\\loveg\\Downloads\\Chatbot_data-master\\ChatbotData.csv\"\n",
    "MODEL_TYPE = \"taeminlee/kogpt2\"\n",
    "OUTPUT_FOLDER = r\"E:\\online_task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained MODEL LOAD\n",
    "- 허깅페이스의 KoGPT2모델 및 tokenizer를 Load합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_TYPE)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset 생성 및 dataloader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConversationDataset(data_path=DATA_PATH)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('부정: 와 진짜 너무 짜증나네</s>',), ('제가 도움이 되고 싶네요.</s>',)]\n"
     ]
    }
   ],
   "source": [
    "for d in data_loader:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# 모델을 GPU로 보냅니다.\n",
    "model = model.to(device)\n",
    "\n",
    "# 모델을 학습하기위해 Optimizer와 scheduler를 선언 합니다.\n",
    "model.train()\n",
    "optimizier = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizier, WARMUP_STEPS, len(data_loader) - WARMUP_STEPS, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장할 곳이 없을 경우 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.mkdir(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_token과 unknown_token을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = torch.tensor(tokenizer.encode(\"<s>\")).unsqueeze(0)\n",
    "unknown_token = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 FineTuning 코드입니다.\n",
    "(전처리 단계에서 미리 Q와 A를 합쳐두는 것이 좋을 것 같습니다.)\n",
    "\n",
    "\n",
    "우선, 해당 코드를 실행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0, started==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae1c20c4a5c462b9e25d9c4d95e228f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train Epoch #0', max=11823.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH : 1, started==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19028e524a5c4b2f8a91c090607d6e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train Epoch #1', max=11823.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH : 2, started==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9afb9f1a2d840479e4c599a3dffcac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train Epoch #2', max=11823.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH : {epoch}, started' + \"=\" * 30)\n",
    "    proc_seq_count = 0\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    temp_count = 0  # 노트북에서 보여드리기 위한 변수입니다.\n",
    "    # 실제 실행시, temp_count와 관련된 코드들은 삭제해주세요.\n",
    "    # 여기 부분\n",
    "    with tqdm(data_loader, desc=\"Train Epoch #{}\".format(epoch)) as t:\n",
    "        for idx, data in enumerate(t):\n",
    "            if temp_count > 5: # 여기\n",
    "                break          # 여기\n",
    "            temp_count += 1    # 여기\n",
    "            Q, A = tokenizer.encode(data[0][0]), tokenizer.encode(data[1][0])\n",
    "            for i in range(len(Q)):\n",
    "                if Q[i] > tokenizer.vocab_size:\n",
    "                    Q[i] = unknown_token\n",
    "            for i in range(len(A)):\n",
    "                if A[i] > tokenizer.vocab_size:\n",
    "                    A[i] = unknown_token\n",
    "\n",
    "            Q = torch.tensor(Q).unsqueeze(0)\n",
    "            A = torch.tensor(A).unsqueeze(0)\n",
    "            temp_conversation = torch.cat([Q, start_token, A], dim=1).to(device)\n",
    "\n",
    "            outputs = model(temp_conversation, labels=temp_conversation)\n",
    "            loss, logits = outputs[:2]\n",
    "            loss.backward()\n",
    "            total_loss += loss.detach().data\n",
    "            total_count += 1\n",
    "            t.set_postfix(loss='{:.6f}'.format(total_loss / total_count))\n",
    "\n",
    "            proc_seq_count += 1\n",
    "            if proc_seq_count == BATCH_SIZE:\n",
    "                proc_seq_count = 0\n",
    "                optimizier.step()\n",
    "                scheduler.step()\n",
    "                optimizier.zero_grad()\n",
    "                scheduler.optimizer.zero_grad()\n",
    "\n",
    "            if idx % 2000 == 1:\n",
    "                torch.save(model.state_dict(), os.path.join(OUTPUT_FOLDER, f\"KoGPT2_KoDialog_{epoch}_{idx}.pt\"))\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_FOLDER, f\"KoGPT2_KoDialog_{epoch}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Generate\n",
    "- FINETUNE_MODEL_PATH : 학습된 모델의 가중치 경로를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_MODEL_PATH = r\"E:\\online_task\\KoGPT2_KoDialog_3.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QnA_Service_MODEL에 해당 가중치를 불러와 load 시켜 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnA_Service_MODEL = GPT2LMHeadModel.from_pretrained(\"taeminlee/kogpt2\")\n",
    "QnA_Service_MODEL.load_state_dict(torch.load(FINETUNE_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"3박4일 정도 놀러가고 싶다\"\n",
    "encoded_text = tokenizer.encode(example_text, add_special_tokens=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  141, 47650, 47514, 47471,  1057,  2211, 47593,  2999,  5314]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\loveg\\Anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:963: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated_sentence = QnA_Service_MODEL.generate(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  141, 47650, 47514, 47471,  1057,  2211, 47593,  2999,  5314, 47440,\n",
       "             1,     0, 18702,  8274, 27043, 47440,     1,     0, 18702,  8274]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(generated_sentence[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3박4일 정도 놀러가고 싶다. 저도 가고 싶어요. 저도 가고'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
